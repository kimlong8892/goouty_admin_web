name: Deploy Admin Dev Cloud Run

on:
  push:
    branches: [ "dev" ]
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: asia-southeast1
  REPO_NAME: goouty-repo
  SERVICE_NAME: goouty-admin-dev
  WORKDIR: .

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: DEV
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Setup for Docker Build
      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker to use gcloud as a credential helper
        run: |
          gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev

      - name: Prepare Environment Variables
        id: env-vars
        env:
          ALL_SECRETS: ${{ toJson(secrets) }}
          ALL_VARS: ${{ toJson(vars) }}
        run: |
          echo "Generating environment variables..."

          # 1. Load public variables from env.json
          if [ -f .github/env-config/dev/env.json ]; then
            # Extract basic vars
            jq -r 'to_entries | .[] | "\(.key)=\(.value)"' .github/env-config/dev/env.json > .env.temp
          else
            echo "PORT=8000" > .env.temp
          fi

          # 2. Load secrets based on secrets.json mapping
          if [ -f .github/env-config/dev/secrets.json ]; then
            jq -n --argjson secrets "$ALL_SECRETS" --argjson vars "$ALL_VARS" --argjson mapping "$(cat .github/env-config/dev/secrets.json)" '
              $mapping | to_entries | .[] |
              .key as $k | .value as $v |
              ($secrets[$v] // $vars[$v]) as $val |
              if $val != null then "\($k)=\($val)" else empty end
            ' -r > .env.secrets

            if [ -f .env.secrets ] && [ -s .env.secrets ]; then
              cat .env.secrets >> .env.temp
            fi
          fi
          
          # 3. Construct DATABASE_URL if not present
          if ! grep -q "DATABASE_URL=" .env.temp; then
            # Check if DB_URL is provided instead
            DB_URL_VAL=$(grep "^DB_URL=" .env.temp | cut -d= -f2- || echo "")
            if [ -n "$DB_URL_VAL" ]; then
                echo "Using DB_URL as DATABASE_URL..."
                echo "DATABASE_URL=${DB_URL_VAL}" >> .env.temp
            else
                echo "Attempting to construct DATABASE_URL from components..."
                DB_HOST=$(grep "^DB_HOST=" .env.temp | cut -d= -f2- || echo "")
                DB_PORT=$(grep "^DB_PORT=" .env.temp | cut -d= -f2- || echo "5432")
                DB_NAME=$(grep "^DB_DATABASE=" .env.temp | cut -d= -f2- || grep "^DB_SCHEMA=" .env.temp | cut -d= -f2- || echo "")
                DB_USER=$(grep "^DB_USERNAME=" .env.temp | cut -d= -f2- || echo "")
                DB_PASS=$(grep "^DB_PASSWORD=" .env.temp | cut -d= -f2- || echo "")
                
                if [ -n "$DB_HOST" ] && [ -n "$DB_USER" ] && [ -n "$DB_PASS" ] && [ -n "$DB_NAME" ]; then
                   echo "Constructing DATABASE_URL..."
                   echo "DATABASE_URL=postgresql://${DB_USER}:${DB_PASS}@${DB_HOST}:${DB_PORT}/${DB_NAME}" >> .env.temp
                fi
            fi
          fi

          # 4. Save to GITHUB_OUTPUT for next step
          {
            echo "ENV_VARS<<EOF"
            cat .env.temp
            echo "EOF"
          } >> $GITHUB_OUTPUT
          
          # Extract PORT for Cloud Run flag
          PORT_VAL=$(grep "^PORT=" .env.temp | cut -d= -f2-)
          if [ -z "$PORT_VAL" ]; then
            PORT_VAL="8000"
          fi
          echo "PORT=$PORT_VAL" >> $GITHUB_OUTPUT

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Generate Prisma Client
        run: |
          export $(grep -v '^#' .env.temp | xargs)
          npx prisma generate

      - name: Build and Push Docker Image
        working-directory: ${{ env.WORKDIR }}
        run: |
          # Export env from .env.temp and pass it to docker build
          export $(grep -v '^#' .env.temp | xargs)
          
          # Build Docker image for dev using the standard Dockerfile
          docker build -f Dockerfile \
            --build-arg DATABASE_URL="$DATABASE_URL" \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/${{ env.SERVICE_NAME }}:${{ github.sha }} .
          # Push image to Artifact Registry
          docker push ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/${{ env.SERVICE_NAME }}:${{ github.sha }}



      - name: Run Database Migration
        continue-on-error: false
        run: |
          echo "Preparing environment variables for Cloud Run Job..."

          if [ ! -s .env.temp ]; then
            echo "::warning::.env.temp is empty. Skipping migration."
            exit 0
          fi

          # Convert .env format to JSON format for gcloud using jq
          # Exclude PORT as it is a reserved name for Cloud Run Jobs
          grep -v '^#' .env.temp | grep -v '^$' | grep -v '^PORT=' | jq -R 'split("=") | select(length>=2) | {(.[0]): (.[1:] | join("="))}' | jq -s 'add' > env-vars.json

          JOB_NAME="migrate-${{ env.SERVICE_NAME }}"

          echo "Deploying/Updating Cloud Run Job: $JOB_NAME"

          # Use prisma migrate deploy directly if installed, or npx prisma
          # We'll use npx to be safe but add --schema for clarity
          
          if gcloud run jobs describe $JOB_NAME --region ${{ env.REGION }} > /dev/null 2>&1; then
             gcloud run jobs update $JOB_NAME \
              --image ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/${{ env.SERVICE_NAME }}:${{ github.sha }} \
              --env-vars-file env-vars.json \
              --command npx \
              --args prisma,migrate,deploy,--schema=./prisma/schema.prisma \
              --region ${{ env.REGION }}
          else
             gcloud run jobs create $JOB_NAME \
              --image ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/${{ env.SERVICE_NAME }}:${{ github.sha }} \
              --env-vars-file env-vars.json \
              --command npx \
              --args prisma,migrate,deploy,--schema=./prisma/schema.prisma \
              --region ${{ env.REGION }}
          fi

          echo "Executing migration..."
          if ! gcloud run jobs execute $JOB_NAME --region ${{ env.REGION }} --wait; then
            echo "Migration failed. Fetching logs..."
            gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=$JOB_NAME AND resource.labels.location=${{ env.REGION }}" --limit=100
            exit 1
          fi

      - name: Deploy to Cloud Run
        uses: google-github-actions/deploy-cloudrun@v2
        with:
          service: ${{ env.SERVICE_NAME }}
          region: ${{ env.REGION }}
          image: ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }}/${{ env.SERVICE_NAME }}:${{ github.sha }}
          env_vars: ${{ steps.env-vars.outputs.ENV_VARS }}
          flags: '--port ${{ steps.env-vars.outputs.PORT }} --allow-unauthenticated'

      - name: Show Cloud Run Service Logs on Failure
        if: failure()
        run: |
          echo "Deployment failed. Fetching latest service logs..."
          gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=${{ env.SERVICE_NAME }} AND resource.labels.location=${{ env.REGION }}" --limit=100
